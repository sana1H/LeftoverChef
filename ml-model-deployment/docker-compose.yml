version: '3.8'

services:
  ml-model:
    build: .
    ports:
      - "5000:5000"
    environment:
      - PORT=5000
    volumes:
      - ./models:/app/models
    restart: unless-stopped

  # Your main backend
  backend:
    build: ../backend
    ports:
      - "8000:8000"
    environment:
      - ML_API_URL=http://ml-model:5000/predict
      - ENABLE_FRESHNESS_DETECTION=true
    depends_on:
      - ml-model
    restart: unless-stopped